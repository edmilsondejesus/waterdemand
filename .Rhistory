# Stores the training execution end time
Fim <- Sys.time()
#Calculate the duration of the training execution
Duration = Fim - Inicio
Duration = round(as.numeric(difftime(time1 =Fim , time2 = Inicio, units = "secs")), 3)
#Get the best params
ar_order<-modelo$arma[1]
ma_order<-modelo$arma[2]
diff_order = modelo$arma[6]
s_ar_order = modelo$arma[3]
s_ma_order = modelo$arma[4]
s_ddiff_order =  modelo$arma[7]
#get best params names
ds_best_param = paste('ARMA(',ar_order,',',diff_order,',',ma_order,')(',s_ar_order,',',s_ddiff_order,',',s_ma_order,')', sep='')
accuracy = accuracy(as.numeric(y_teste), as.numeric(predicao$mean))
ME <-accuracy[1,1]
RMSE <-accuracy[1,2]
MSE <- RMSE * RMSE
MAE <-accuracy[1,3]
MPE <-accuracy[1,4]
MAPE <-accuracy[1,5]
salvar_resultado(sk_ponto, ds_best_param, n_time_steps, MSE, RMSE, MAE, MAPE, Duration)
#plot result of prediction
#plot(predicao)
#plot(as.numeric(y_teste), type = 'l', main = "Validação", xlab = "Tempo em horas", ylab = "Consumo l/h")
#lines(as.numeric(predicao$mean), col='blue')
#analysis of the metrics found in the model for the training phase
#accuracy(y_treino, modelo$fitted)
}
#get list of sk_ponto
lista_pontos=unique(ds_water['SK_PONTO'])
tamanho=count(lista_pontos)
# make prediction for each sk_ponto
for (x in 1:tamanho$n){
sk_ponto=lista_pontos[x,1]
ds_ponto <- ds_water[ds_water$SK_PONTO==sk_ponto$SK_PONTO,]
for (n_time_Steps in 1:6){
print(paste('prediction sk_ponto=',sk_ponto$SK_PONTO,' lag times = ',n_time_Steps, sep=''))
print(paste('ds_ponto = ',count(ds_ponto),' lines', sep=''))
#
previsao_ARIMA2(sk_ponto$SK_PONTO, ds_ponto, n_time_Steps)
}
}
library(lmtest)
library(forecast)
library(xts)
#install.packages('fpp2')
library(lmtest)
library(tseries)
#install.packages('astsa')
library(astsa)
library(plyr)
library(lubridate)
#install.packages("TSA")
library(TSA)
library(stringr)
library(dplyr)
caminho = paste("C:/Users/Edmilson/Downloads/mestrado/waterdemand/", sep="")
source(paste(caminho,"basic.r",sep = ""))
caminho = paste("C:/Users/Edmilson/Downloads/mestrado/waterdemand/data/", sep="")
arquivo <- 'DS_Agua_2017_2022_por_ponto.csv'
rm(ds_water)
ds_water <- read.csv(paste(caminho,arquivo, sep=""), header = TRUE, sep = ";", encoding = 'latin1')
#Grouping data for Week
#Grouping data for Day
ds_water[c('DATA')]<-str_split_fixed(ds_water$DT_MEDICAO_HORA,' ',1)
ds_water$DATA<-as_date(ds_water$DATA)
#ds_water$WEEK <- as.numeric(strftime(ds_water$DATA, format = "%Y"))*100 + as.numeric(strftime(ds_water$DATA, format = "%V"))
ds_water$WEEK <- as.numeric(format(ds_water$DATA, "%G%V"))
head(ds_water)
#colnames(ds_matrix) <- c("DT_MEDICAO_HORA","VL_MEDICAO","PRECIPITACAO","PRESSAO","TEMPERATURA","UMIDADE","VELOCIDADE_VENTO","VL_RESULTADO")
ds_water <- ds_water %>% group_by(SK_PONTO, WEEK) %>%
summarize(PRECIPITACAO = sum(PRECIPITACAO), PRESSAO_ATMOSFERICA=mean(PRESSAO_ATMOSFERICA),
TEMPERATURA_DO_AR_C=mean(TEMPERATURA_DO_AR_C), UMIDADE_RELATIVA_DO_AR=mean(UMIDADE_RELATIVA_DO_AR),
VELOCIDADE_VENTO=mean(VELOCIDADE_VENTO),VL_MEDICAO=sum(VL_MEDICAO), .groups='drop') %>%
arrange(SK_PONTO,WEEK)
caminho_result = paste("C:/Users/Edmilson/Downloads/mestrado/waterdemand/results/", sep="")
arquivo_result = 'Result_ARIMA2_Model_Week.csv'
salvar_resultado <- function (sk_ponto, ds_best_param, n_time_steps, MSE, RMSE, MAE, MAPE, Duration){
#Script to write training cycle results
data = data.frame(sk_ponto = sk_ponto, ds_best_param = ds_best_param,
n_time_steps = n_time_steps, MSE = MSE, RMSE = RMSE,
MAE = MAE, MAPE = MAPE, Duration = Duration)
write.table(data,paste(caminho_result,arquivo_result, sep=""),sep=';',append = TRUE, col.names = FALSE, row.names = FALSE, dec = ',')
}
#Script to create the results file
criar_arquivo_resultado <- function(){
data = data.frame(sk_ponto = '', ds_best_param = '',
n_time_steps = '', MSE = '', RMSE = '',
MAE = '', MAPE = '', Duration = '')
write.table(data,paste(caminho_result,arquivo_result, sep=""), sep=';')
}
criar_arquivo_resultado ()
previsao_ARIMA2 <- function (sk_ponto, ds_ponto, n_time_steps){
#ds_ponto$DATA<- as_datetime(ds_ponto$DATA)
ds_st<-cbind(ds_ponto$WEEK,ds_ponto$VL_MEDICAO,ds_ponto$PRECIPITACAO, ds_ponto$PRESSAO_ATMOSFERICA, ds_ponto$TEMPERATURA_DO_AR_C,
ds_ponto$UMIDADE_RELATIVA_DO_AR, ds_ponto$VELOCIDADE_VENTO)
# time serire transform - shift of n_time_steps lag time
for (i in 1:n_time_steps){
if(i>1)
ds_stlag <- cbind(ds_stlag,lag.xts(ds_ponto$VL_MEDICAO, k = i))
else
ds_stlag <- cbind(ds_st,lag.xts(ds_ponto$VL_MEDICAO, k = i))
}
#Concatenates the matrix with the result vector and eliminates the last line
ds_matrix <- na.omit(ds_stlag)
#colnames(ds_matrix) <- c("DT_MEDICAO_HORA","VL_MEDICAO","PRECIPITACAO","PRESSAO","TEMPERATURA","UMIDADE","VELOCIDADE_VENTO","VL_RESULTADO")
new_index <- ds_matrix[,1]
ds_matrix <- ds_matrix[,2:ncol(ds_matrix)]
#head(ts_matrix)
#Plot all series
#ts_matrix <- xts(ds_matrix, order.by = new_index)
#autoplot(ts_matrix)
#Plot VL_MEDICAO
#autoplot(ts_matrix[,1])
#Check the stationarity of the VL_MEDICAO series
#adf.test(ds_matrix[,1])
# Check the autocorrelation and partial autocorrelation functions
#acf2(as.numeric(ds_matrix[,1]))
d_resultado <-ds_matrix[,1]
# BoxCox transformation for hourly prediction
lambda<- BoxCox.lambda(ds_matrix[,1])
# Stores the training execution start time
Inicio <- Sys.time()
#Search the best ARIMA model without lambda
print(ds_matrix)
modelo=auto.arima(ds_matrix[,1],xreg=ds_matrix[,2:ncol(ds_matrix)], trace = TRUE,approximation = FALSE, max.p = 5, max.q = 5, lambda = "auto" )
#identify index number for separate data of treain 75% and test 25%
idx_teste <- round(length(d_resultado)* 0.75)
idx_validacao <-length(d_resultado)
# Adjustment of the result series for training x test
y_treino <- ts(d_resultado[1:idx_teste], frequency = 52)
y_teste  <- ts(d_resultado[(idx_teste +1):idx_validacao], frequency = 52)
#adjustment of series of independent variables for training x testing
X_treino <- ts(ds_matrix[1:idx_teste,2:ncol(ds_matrix)], frequency = 52)
X_teste <- ts(ds_matrix[(idx_teste +1):idx_validacao, 2:ncol(ds_matrix)], frequency = 52)
#make prediction
predicao <- forecast(modelo, h=length(y_teste), xreg = X_teste)
# Stores the training execution end time
Fim <- Sys.time()
#Calculate the duration of the training execution
Duration = Fim - Inicio
Duration = round(as.numeric(difftime(time1 =Fim , time2 = Inicio, units = "secs")), 3)
#Get the best params
ar_order<-modelo$arma[1]
ma_order<-modelo$arma[2]
diff_order = modelo$arma[6]
s_ar_order = modelo$arma[3]
s_ma_order = modelo$arma[4]
s_ddiff_order =  modelo$arma[7]
#get best params names
ds_best_param = paste('ARIMA(',ar_order,',',diff_order,',',ma_order,')(',s_ar_order,',',s_ddiff_order,',',s_ma_order,')', sep='')
accuracy = accuracy(as.numeric(y_teste), as.numeric(predicao$mean))
ME <-accuracy[1,1]
RMSE <-accuracy[1,2]
MSE <- RMSE * RMSE
MAE <-accuracy[1,3]
MPE <-accuracy[1,4]
MAPE <-accuracy[1,5]
salvar_resultado(sk_ponto, ds_best_param, n_time_steps, MSE, RMSE, MAE, MAPE, Duration)
#plot result of prediction
#plot(predicao)
#plot(as.numeric(y_teste), type = 'l', main = "Validação", xlab = "Tempo em horas", ylab = "Consumo l/h")
#lines(as.numeric(predicao$mean), col='blue')
#analysis of the metrics found in the model for the training phase
#accuracy(y_treino, modelo$fitted)
}
#get list of sk_ponto
lista_pontos=unique(ds_water['SK_PONTO'])
tamanho=count(lista_pontos)
# make prediction for each sk_ponto
for (x in 1:tamanho$n){
sk_ponto=lista_pontos[x,1]
ds_ponto <- ds_water[ds_water$SK_PONTO==sk_ponto$SK_PONTO,]
for (n_time_Steps in 1:6){
print(paste('prediction sk_ponto=',sk_ponto$SK_PONTO,' lag times = ',n_time_Steps, sep=''))
print(paste('ds_ponto = ',count(ds_ponto),' lines', sep=''))
previsao_ARIMA2(sk_ponto$SK_PONTO, ds_ponto, n_time_Steps)
}
}
library(lmtest)
library(forecast)
library(xts)
#install.packages('fpp2')
library(lmtest)
library(tseries)
#install.packages('astsa')
library(astsa)
library(plyr)
library(lubridate)
#install.packages("TSA")
library(TSA)
library(stringr)
library(dplyr)
caminho = paste("C:/Users/Edmilson/Downloads/mestrado/waterdemand/", sep="")
source(paste(caminho,"basic.r",sep = ""))
caminho = paste("C:/Users/Edmilson/Downloads/mestrado/waterdemand/data/", sep="")
arquivo <- 'DS_Agua_2017_2022_por_ponto.csv'
rm(ds_water)
ds_water <- read.csv(paste(caminho,arquivo, sep=""), header = TRUE, sep = ";", encoding = 'latin1')
#Grouping data for Week
#Grouping data for Day
ds_water[c('DATA')]<-str_split_fixed(ds_water$DT_MEDICAO_HORA,' ',1)
ds_water$DATA<-as_date(ds_water$DATA)
#ds_water$WEEK <- as.numeric(strftime(ds_water$DATA, format = "%Y"))*100 + as.numeric(strftime(ds_water$DATA, format = "%V"))
ds_water$WEEK <- as.numeric(format(ds_water$DATA, "%G%V"))
head(ds_water)
#colnames(ds_matrix) <- c("DT_MEDICAO_HORA","VL_MEDICAO","PRECIPITACAO","PRESSAO","TEMPERATURA","UMIDADE","VELOCIDADE_VENTO","VL_RESULTADO")
ds_water <- ds_water %>% group_by(SK_PONTO, WEEK) %>%
summarize(PRECIPITACAO = sum(PRECIPITACAO), PRESSAO_ATMOSFERICA=mean(PRESSAO_ATMOSFERICA),
TEMPERATURA_DO_AR_C=mean(TEMPERATURA_DO_AR_C), UMIDADE_RELATIVA_DO_AR=mean(UMIDADE_RELATIVA_DO_AR),
VELOCIDADE_VENTO=mean(VELOCIDADE_VENTO),VL_MEDICAO=sum(VL_MEDICAO), .groups='drop') %>%
arrange(SK_PONTO,WEEK)
caminho_result = paste("C:/Users/Edmilson/Downloads/mestrado/waterdemand/results/", sep="")
arquivo_result = 'Result_ARIMA2_Model_Week.csv'
salvar_resultado <- function (sk_ponto, ds_best_param, n_time_steps, MSE, RMSE, MAE, MAPE, Duration){
#Script to write training cycle results
data = data.frame(sk_ponto = sk_ponto, ds_best_param = ds_best_param,
n_time_steps = n_time_steps, MSE = MSE, RMSE = RMSE,
MAE = MAE, MAPE = MAPE, Duration = Duration)
write.table(data,paste(caminho_result,arquivo_result, sep=""),sep=';',append = TRUE, col.names = FALSE, row.names = FALSE, dec = ',')
}
#Script to create the results file
criar_arquivo_resultado <- function(){
data = data.frame(sk_ponto = '', ds_best_param = '',
n_time_steps = '', MSE = '', RMSE = '',
MAE = '', MAPE = '', Duration = '')
write.table(data,paste(caminho_result,arquivo_result, sep=""), sep=';')
}
criar_arquivo_resultado ()
previsao_ARIMA2 <- function (sk_ponto, ds_ponto, n_time_steps){
#ds_ponto$DATA<- as_datetime(ds_ponto$DATA)
ds_st<-cbind(ds_ponto$WEEK,ds_ponto$VL_MEDICAO,ds_ponto$PRECIPITACAO, ds_ponto$PRESSAO_ATMOSFERICA, ds_ponto$TEMPERATURA_DO_AR_C,
ds_ponto$UMIDADE_RELATIVA_DO_AR, ds_ponto$VELOCIDADE_VENTO)
# time serire transform - shift of n_time_steps lag time
for (i in 1:n_time_steps){
if(i>1)
ds_stlag <- cbind(ds_stlag,lag.xts(ds_ponto$VL_MEDICAO, k = i))
else
ds_stlag <- cbind(ds_st,lag.xts(ds_ponto$VL_MEDICAO, k = i))
}
#Concatenates the matrix with the result vector and eliminates the last line
ds_matrix <- na.omit(ds_stlag)
#colnames(ds_matrix) <- c("DT_MEDICAO_HORA","VL_MEDICAO","PRECIPITACAO","PRESSAO","TEMPERATURA","UMIDADE","VELOCIDADE_VENTO","VL_RESULTADO")
new_index <- ds_matrix[,1]
ds_matrix <- ds_matrix[,2:ncol(ds_matrix)]
#head(ts_matrix)
#Plot all series
#ts_matrix <- xts(ds_matrix, order.by = new_index)
#autoplot(ts_matrix)
#Plot VL_MEDICAO
#autoplot(ts_matrix[,1])
#Check the stationarity of the VL_MEDICAO series
#adf.test(ds_matrix[,1])
# Check the autocorrelation and partial autocorrelation functions
#acf2(as.numeric(ds_matrix[,1]))
d_resultado <-ds_matrix[,1]
# BoxCox transformation for hourly prediction
lambda<- BoxCox.lambda(ds_matrix[,1])
# Stores the training execution start time
Inicio <- Sys.time()
#Search the best ARIMA model without lambda
print(ds_matrix)
modelo=auto.arima(ds_matrix[,1],xreg=ds_matrix[,2:ncol(ds_matrix)], trace = TRUE,approximation = FALSE, max.p = 5, max.q = 5, lambda = lambda )
#identify index number for separate data of treain 75% and test 25%
idx_teste <- round(length(d_resultado)* 0.75)
idx_validacao <-length(d_resultado)
# Adjustment of the result series for training x test
y_treino <- ts(d_resultado[1:idx_teste], frequency = 52)
y_teste  <- ts(d_resultado[(idx_teste +1):idx_validacao], frequency = 52)
#adjustment of series of independent variables for training x testing
X_treino <- ts(ds_matrix[1:idx_teste,2:ncol(ds_matrix)], frequency = 52)
X_teste <- ts(ds_matrix[(idx_teste +1):idx_validacao, 2:ncol(ds_matrix)], frequency = 52)
#make prediction
predicao <- forecast(modelo, h=length(y_teste), xreg = X_teste)
# Stores the training execution end time
Fim <- Sys.time()
#Calculate the duration of the training execution
Duration = Fim - Inicio
Duration = round(as.numeric(difftime(time1 =Fim , time2 = Inicio, units = "secs")), 3)
#Get the best params
ar_order<-modelo$arma[1]
ma_order<-modelo$arma[2]
diff_order = modelo$arma[6]
s_ar_order = modelo$arma[3]
s_ma_order = modelo$arma[4]
s_ddiff_order =  modelo$arma[7]
#get best params names
ds_best_param = paste('ARIMA(',ar_order,',',diff_order,',',ma_order,')(',s_ar_order,',',s_ddiff_order,',',s_ma_order,')', sep='')
accuracy = accuracy(as.numeric(y_teste), as.numeric(predicao$mean))
ME <-accuracy[1,1]
RMSE <-accuracy[1,2]
MSE <- RMSE * RMSE
MAE <-accuracy[1,3]
MPE <-accuracy[1,4]
MAPE <-accuracy[1,5]
salvar_resultado(sk_ponto, ds_best_param, n_time_steps, MSE, RMSE, MAE, MAPE, Duration)
#plot result of prediction
#plot(predicao)
#plot(as.numeric(y_teste), type = 'l', main = "Validação", xlab = "Tempo em horas", ylab = "Consumo l/h")
#lines(as.numeric(predicao$mean), col='blue')
#analysis of the metrics found in the model for the training phase
#accuracy(y_treino, modelo$fitted)
}
#get list of sk_ponto
lista_pontos=unique(ds_water['SK_PONTO'])
tamanho=count(lista_pontos)
# make prediction for each sk_ponto
for (x in 1:tamanho$n){
sk_ponto=lista_pontos[x,1]
ds_ponto <- ds_water[ds_water$SK_PONTO==sk_ponto$SK_PONTO,]
for (n_time_Steps in 1:6){
print(paste('prediction sk_ponto=',sk_ponto$SK_PONTO,' lag times = ',n_time_Steps, sep=''))
print(paste('ds_ponto = ',count(ds_ponto),' lines', sep=''))
previsao_ARIMA2(sk_ponto$SK_PONTO, ds_ponto, n_time_Steps)
}
}
show_error< function(e){
print(e)
}
show_error<- function(e){
print(e)
}
#get list of sk_ponto
lista_pontos=unique(ds_water['SK_PONTO'])
tamanho=count(lista_pontos)
# make prediction for each sk_ponto
for (x in 1:tamanho$n){
sk_ponto=lista_pontos[x,1]
ds_ponto <- ds_water[ds_water$SK_PONTO==sk_ponto$SK_PONTO,]
for (n_time_Steps in 1:6){
print(paste('prediction sk_ponto=',sk_ponto$SK_PONTO,' lag times = ',n_time_Steps, sep=''))
print(paste('ds_ponto = ',count(ds_ponto),' lines', sep=''))
tryCatch(previsao_ARIMA2(sk_ponto$SK_PONTO, ds_ponto, n_time_Steps), error=show_error)
}
}
# Federal University of Bahia
# Computer Science Department
# Graduate Program in Computing
# Masters' Degree in Computer Science
# Student: Edmilson de Jesus
# Advisor: Gecynalda Gomes
#Date: 7/2/2022
#Topic: Water demand forecast for Salvador and Metropolitan Region using AI models
#Carrega pacote readxl
library(readxl)
#bibliotecal sql
library(sqldf)
#Instala pacote de escrita para arquivos excel
#install.packages("writexl")
#Carrega pacote wirtexl
#library(writexl)
#install.packages("plotly")
library(plotly)
# Carrega pacote forecast
library(forecast)
# Carrega
#install.packages("ggplot2")
library(ggplot2)
library(reshape2)
#Carrega package tidyverse
library(tidyverse)
#Para descarregar o pacote
#detach("package:tidyverse", unload = TRUE)
# Instala pacote zoo de médias móveis
#install.packages("zoo",dependences = TRUE)
library(zoo) # pacote com função para médias móveis
# Carrega pacote de manipulação otimizada de strings
library(stringr)
#Carrega package lubirdate  para trabalhar com data/hora
library(lubridate)
# Retorna data e hora no momento da execução
# base::date()
day <- today()
rm(day)
library(scales)
library(tidyr)
library(dplyr)
library(e1071)
library(BSDA)
caminho = paste("C:/Users/Edmilson/Downloads/mestrado/waterdemand/", sep="")
source(paste(caminho,"basic.r",sep = ""))
caminho = paste("C:/Users/Edmilson/Downloads/mestrado/waterdemand/data/", sep="")
#--------------------   Introdução: Conhecendo instâncias x atributos x valores  ----------
dados_consumo <- read.csv(paste(caminho,"DADOS_TELEMETRIA_2017_a_2022RMS.csv", sep=""), header = TRUE, sep = ";", encoding = 'latin1')
#head(dados_consumo)
#View(dados_consumo)
#Verify null fields
#count.nas(dados_consumo)
info(dados_consumo)
#Boxplot of booking points
boxplot(dados_consumo$VL_MEDICAO~dados_consumo$SK_PONTO)
#--------------------   Limpeza: Identificação e substituição de dados inválidos ----------
#copia a data original
dados_consumo$DT_ORIGINAL<-dados_consumo$DT_MEDICAO
class(dados_consumo$DT_MEDICAO)
#View(dados_consumo)
df_lista <- ds_consumo %>% group_by(SK_PONTO, NM_PONTO) %>%
summarize(VL_MEDICAO=sum(VL_MEDICAO)) %>%
arrange(SK_PONTO)
#List of present reservoirs from the data_consumo dataset
#Total of 13 sk_points, with reservoir R7 consisting of the sum of sk_point 2 to sk_point 3
# character date to date conversion
dados_consumo$DT_MEDICAO <- as.Date(parse_date_time(dados_consumo$DT_ORIGINAL, "%y-%m-%d-%H.%M.%S"))
class(dados_consumo$DT_MEDICAO)
# character date conversion to datetime in hours
dados_consumo$DT_MEDICAO_HORA <- as_datetime(parse_date_time(dados_consumo$DT_ORIGINAL, "%y-%m-%d-%H.%M.%S"))
class(dados_consumo$DT_MEDICAO_HORA)
#class(dados_consumo$VL_MEDICAO)
#dados_consumo$VL_MEDICAO=as.numeric(trimws(dados_consumo$VL_MEDICAO))
#class(dados_consumo$VL_MEDICAO)
dados_consumo$NN_DIAMES=day(dados_consumo$DT_MEDICAO)
# Get the dataset with the data of each point
ds_skp1 <- subset(dados_consumo, SK_PONTO==1 & DT_MEDICAO_HORA >= as_datetime(parse_date_time('2019-04-01-16.00.00.000000', "%y-%m-%d-%H.%M.%S")))
ds_skp2 <- subset(dados_consumo, SK_PONTO==2 & DT_MEDICAO_HORA >= as_datetime(parse_date_time('2017-11-08-12.00.00.000000', "%y-%m-%d-%H.%M.%S")))
ds_skp3 <- subset(dados_consumo, SK_PONTO==3 & DT_MEDICAO_HORA >= as_datetime(parse_date_time('2017-11-08-12.00.00.000000', "%y-%m-%d-%H.%M.%S")))
ds_skp4 <- subset(dados_consumo, SK_PONTO==4)
ds_skp5 <- subset(dados_consumo, SK_PONTO==5)
ds_skp6 <- subset(dados_consumo, SK_PONTO==6)
ds_skp7 <- subset(dados_consumo, SK_PONTO==7)
ds_skp8 <- subset(dados_consumo, SK_PONTO==8 & DT_MEDICAO_HORA >= as_datetime(parse_date_time('2017-11-27-00.00.00.000000', "%y-%m-%d-%H.%M.%S")))
ds_skp9 <- subset(dados_consumo, SK_PONTO==9 & DT_MEDICAO_HORA >= as_datetime(parse_date_time('2019-11-08-16.00.00.000000', "%y-%m-%d-%H.%M.%S")))
ds_skp10 <- subset(dados_consumo, SK_PONTO==10 & DT_MEDICAO_HORA >= as_datetime(parse_date_time('2022-05-30-00.00.00.000000', "%y-%m-%d-%H.%M.%S")))
ds_skp11 <- subset(dados_consumo, SK_PONTO==11)
ds_skp12 <- subset(dados_consumo, SK_PONTO==12)
# taking the descriptive measures
#Join data of  ds_skip 2 and 3 to ds_skip13 for reservoir  R7 data
ds_skp13 <-sqldf::sqldf('select sum(a.VL_MEDICAO + b.VL_MEDICAO) as VL_MEDICAO, 13 as SK_PONTO, a.DT_MEDICAO, 0 as NN_QUALIDADE, a.NN_ANO, \'ETA PRINCIPAL - R7 \' as NM_PONTO, a.DT_ORIGINAL, a.DT_MEDICAO_HORA, a.NN_DIAMES from ds_skp3 b inner join ds_skp2 a on b.DT_ORIGINAL=a.DT_ORIGINAL group by a.DT_MEDICAO, a.DT_ORIGINAL, a.DT_MEDICAO_HORA, a.NN_ANO, a.NN_DIAMES')
ds_skp13$DT_MEDICAO_HORA <- as_datetime(parse_date_time(ds_skp13$DT_ORIGINAL, "%y-%m-%d-%H.%M.%S"))
summary_gecy(ds_skp1$VL_MEDICAO)
summary_gecy(ds_skp2$VL_MEDICAO)
summary_gecy(ds_skp3$VL_MEDICAO)
summary_gecy(ds_skp4$VL_MEDICAO)
summary_gecy(ds_skp5$VL_MEDICAO)
summary_gecy(ds_skp6$VL_MEDICAO)
summary_gecy(ds_skp7$VL_MEDICAO)
summary_gecy(ds_skp8$VL_MEDICAO)
summary_gecy(ds_skp9$VL_MEDICAO)
summary_gecy(ds_skp10$VL_MEDICAO)
summary_gecy(ds_skp11$VL_MEDICAO)
summary_gecy(ds_skp12$VL_MEDICAO)
summary_gecy(ds_skp13$VL_MEDICAO)
#R1 Dunas - remove major outliers
show_plot_skp(ds_skp1)
ds_skp1<-remove_outliers(ds_skp1)
show_plot_skp(ds_skp1)
#remove major outliers
ds_skp2<-remove_outliers(ds_skp2)
ds_skp3<-remove_outliers(ds_skp3)
ds_skp4<-remove_outliers(ds_skp4)
ds_skp5<-remove_outliers(ds_skp5)
ds_skp6<-remove_outliers(ds_skp6)
ds_skp7<-remove_outliers(ds_skp7)
ds_skp8<-remove_outliers(ds_skp8)
ds_skp9<-remove_outliers(ds_skp9)
ds_skp10<-remove_outliers(ds_skp10)
ds_skp11<-remove_outliers(ds_skp11)
ds_skp12<-remove_outliers(ds_skp12)
#use this function to generate art combination at 500 dpi, print and save on jpg
#method que funciona
#jpeg('C:\\Users\\Edmilson\\Downloads\\mestrado\\Orientacao\\artigo01\\Latex\\figures\\FIG3.jpg', quality = 100, res = 500, width=1772, height=1528)
tiff('C:\\Users\\Edmilson\\Downloads\\mestrado\\Orientacao\\artigo03\\Latex\\figures\\Fig3.tiff', quality = 100, res = 1000, width=3543, height=3055)
#use this function to generate art combination at 500 dpi, print and save on jpg
#method que funciona
#jpeg('C:\\Users\\Edmilson\\Downloads\\mestrado\\Orientacao\\artigo01\\Latex\\figures\\FIG3.jpg', quality = 100, res = 500, width=1772, height=1528)
tiff('C:\\Users\\Edmilson\\Downloads\\mestrado\\Orientacao\\artigo03\\Latex\\figures\\Fig3.tiff', res = 1000, width=3543, height=3055)
par(mfrow=c(1,1))
#ggplot(data = ds_skp13, aes(x = DT_MEDICAO_HORA, y = VL_MEDICAO)) + geom_point(size = 0.2) + geom_line(color = "blue", size = 0.2)  + labs(x = "Time in hours", y = "Consumption l/h")
ggplot(data = ds_skp13, aes(x = DT_MEDICAO_HORA, y = VL_MEDICAO)) + geom_point(size = 0.2) +
geom_line(color = "blue", size = 0.2)  + labs(x = "Time in hours", y = "Consumption l/h", )+
theme(axis.text=element_text(size=6),
axis.title=element_text(size=6))
dev.off()
ds_skp13<-remove_outliers(ds_skp13)
ds_skp1 <- ds_skp1[order(ds_skp1$DT_MEDICAO_HORA),]
ds_skp2 <- ds_skp2[order(ds_skp2$DT_MEDICAO_HORA),]
ds_skp3 <- ds_skp3[order(ds_skp3$DT_MEDICAO_HORA),]
ds_skp4 <- ds_skp4[order(ds_skp4$DT_MEDICAO_HORA),]
ds_skp5 <- ds_skp5[order(ds_skp5$DT_MEDICAO_HORA),]
ds_skp6 <- ds_skp6[order(ds_skp6$DT_MEDICAO_HORA),]
ds_skp7 <- ds_skp7[order(ds_skp7$DT_MEDICAO_HORA),]
ds_skp8 <- ds_skp8[order(ds_skp8$DT_MEDICAO_HORA),]
ds_skp9 <- ds_skp9[order(ds_skp9$DT_MEDICAO_HORA),]
ds_skp10 <- ds_skp10[order(ds_skp10$DT_MEDICAO_HORA),]
ds_skp11 <- ds_skp11[order(ds_skp11$DT_MEDICAO_HORA),]
ds_skp12 <- ds_skp12[order(ds_skp12$DT_MEDICAO_HORA),]
ds_skp13 <- ds_skp13[order(ds_skp13$DT_MEDICAO_HORA),]
#elimina valores negativos
ds_skp1 <- replace_consumo_negativo(ds_skp1, 3)
ds_skp2 <- replace_consumo_negativo(ds_skp2, 3)
ds_skp3 <- replace_consumo_negativo(ds_skp3, 3)
ds_skp4 <- replace_consumo_negativo(ds_skp4, 3)
ds_skp5 <- replace_consumo_negativo(ds_skp5, 3)
ds_skp6 <- replace_consumo_negativo(ds_skp6, 3)
ds_skp7 <- replace_consumo_negativo(ds_skp7, 3)
ds_skp8 <- replace_consumo_negativo(ds_skp8, 3)
ds_skp9 <- replace_consumo_negativo(ds_skp9, 3)
ds_skp10 <- replace_consumo_negativo(ds_skp10, 3)
ds_skp11 <- replace_consumo_negativo(ds_skp11, 3)
ds_skp12 <- replace_consumo_negativo(ds_skp12, 3)
ds_skp13 <- replace_consumo_negativo(ds_skp13, 3)
#or
tiff('C:\\Users\\Edmilson\\Downloads\\mestrado\\Orientacao\\artigo03\\Latex\\figures\\Fig4.jpg',  res = 1000, width=3543, height=3055)
#or
tiff('C:\\Users\\Edmilson\\Downloads\\mestrado\\Orientacao\\artigo03\\Latex\\figures\\Fig4.tiff',  res = 1000, width=3543, height=3055)
par(mfrow=c(1,1))
#ggplot(data = ds_skp13, aes(x = DT_MEDICAO_HORA, y = VL_MEDICAO)) + geom_point()
ggplot(data = ds_skp13, aes(x = DT_MEDICAO_HORA, y = VL_MEDICAO)) + geom_point(size = 0.2) +
geom_line(color = "blue", size = 0.2)  + labs(x = "Time in hours", y = "Consumption l/h", )+
theme(axis.text=element_text(size=6),
axis.title=element_text(size=6))
dev.off()
